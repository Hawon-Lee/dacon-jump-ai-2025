{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7a7fa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tech/Hawon/dacon-jump-ai-2025/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at DeepChem/ChemBERTa-77M-MTR and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import Data, Batch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "sys.path.append(\"../src/\")\n",
    "from preprocess import get_descriptors_2d, get_descriptors_3d, get_ecfp, MolPreprocessor\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\")\n",
    "model = AutoModel.from_pretrained(\"DeepChem/ChemBERTa-77M-MTR\")\n",
    "\n",
    "\n",
    "def get_chemberta_emb_single(\n",
    "    tokenizer, model, smiles: str, device=\"cuda:0\", max_len=256\n",
    ") -> tuple[torch.Tensor]:\n",
    "\n",
    "    input = tokenizer(\n",
    "        smiles,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input)\n",
    "        last_hidden = outputs.last_hidden_state\n",
    "        cls_emb = last_hidden[:, 0, :]\n",
    "        pooled_atom_emb = last_hidden[:, 1:-1, :].mean(axis=1)\n",
    "    \n",
    "    return cls_emb, pooled_atom_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff054bff",
   "metadata": {},
   "source": [
    "### SMILES 로부터 descriptor, ChemBerta embedding, graph 특징 추출 및 데이터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "947870a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['smiles', 'ic50_nm', 'ic50_nm_imputed', 'is_active(10um)',\n",
       "       'data_source', 'data_id', 'pvalue', 'pvalue_imputed', 'rdmol',\n",
       "       'rdmol_confs5', 'medai_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../data/250714_preprocessed_HW_V2.pkl\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993e892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25753/25753 [08:46<00:00, 48.95it/s]\n"
     ]
    }
   ],
   "source": [
    "save2dir = \"../data/250716_input_preparation_hw\"\n",
    "mp = MolPreprocessor()\n",
    "\n",
    "# 컬럼 인덱스 계산\n",
    "smiles_idx = df.columns.get_loc('smiles')\n",
    "pvalue_idx = df.columns.get_loc('pvalue')\n",
    "pvalue_imputed_idx = df.columns.get_loc('pvalue_imputed')\n",
    "rdmol_idx = df.columns.get_loc('rdmol_confs5')\n",
    "mol_id_idx = df.columns.get_loc('medai_id')\n",
    "is_active_idx = df.columns.get_loc('is_active(10um)')\n",
    "\n",
    "for i in tqdm(range(df.shape[0])):\n",
    "    smiles = df.iloc[i, smiles_idx]\n",
    "    pvalue = df.iloc[i, pvalue_idx]\n",
    "    pvalue_imputed = df.iloc[i, pvalue_imputed_idx]\n",
    "    rd_mol = df.iloc[i, rdmol_idx]\n",
    "    mol_id = df.iloc[i, mol_id_idx]\n",
    "    is_active = df.iloc[i, is_active_idx]\n",
    "    \n",
    "    # Feature 계산\n",
    "    desc_2d = get_descriptors_2d(rd_mol).unsqueeze(0)\n",
    "    desc_3d = get_descriptors_3d(rd_mol).unsqueeze(0)\n",
    "    ecfp = get_ecfp(rd_mol, radius=2, fpSize=2048).unsqueeze(0)\n",
    "    \n",
    "    # pyg Data 객체 형태로 만들기\n",
    "    data = Data()\n",
    "\n",
    "    # ChemBerta emb 추가\n",
    "    cls_emb, pooled_atom_emb = get_chemberta_emb_single(tokenizer=tokenizer, model=model, smiles=smiles)\n",
    "    data.chemberta_cls = cls_emb\n",
    "    data.chemberta_mol = pooled_atom_emb\n",
    "\n",
    "    # Graph feature 추가\n",
    "    data.x = mp.get_lig_feature(rd_mol, to_tensor=True)\n",
    "    data.edge_index, data.edge_attr = mp.get_edge_info(rd_mol)\n",
    "    data.pos = mp.get_atom_position(rd_mol)\n",
    "    data.z = mp.get_atomic_number(rd_mol)\n",
    "\n",
    "    # Descriptor, FP 추가\n",
    "    data.desc_2d = desc_2d\n",
    "    data.desc_3d = desc_3d\n",
    "    data.ecfp = ecfp\n",
    "\n",
    "    # 저장\n",
    "    torch.save(data, f\"{save2dir}/{mol_id}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5b158b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tech/Hawon/dacon-jump-ai-2025/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Data(chemberta_cls=[1, 384], chemberta_mol=[1, 384], x=[18, 54], edge_index=[2, 38], edge_attr=[38], pos=[18, 5, 3], z=[18], desc_2d=[1, 6], desc_3d=[1, 11], ecfp=[1, 2048])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.load(\"/home/tech/Hawon/dacon-jump-ai-2025/data/preprocessed/Medai_00000.pt\", weights_only=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
