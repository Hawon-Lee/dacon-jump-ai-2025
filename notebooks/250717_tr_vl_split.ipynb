{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1c216",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.rdFingerprintGenerator import GetMorganGenerator\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from typing import Tuple, Optional\n",
    "import warnings\n",
    "import json\n",
    "\n",
    "def ecfp_cluster_train_val_split(\n",
    "    df: pd.DataFrame,\n",
    "    val_ratio: float = 0.2,\n",
    "    smiles_col: str = 'smiles',\n",
    "    mol_col: Optional[str] = 'rdmol_confs5',\n",
    "    ecfp_radius: int = 2,\n",
    "    ecfp_bits: int = 2048,\n",
    "    n_clusters: Optional[int] = None,\n",
    "    random_state: int = 42\n",
    ") -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    ECFP 기반 클러스터링을 통해 train/validation set을 분리하는 함수\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        분리할 데이터프레임\n",
    "    val_ratio : float, default=0.2\n",
    "        validation set 비율 (0~1)\n",
    "    smiles_col : str, default='smiles'\n",
    "        SMILES 문자열이 있는 컬럼명\n",
    "    mol_col : str, optional, default='rdmol_confs5'\n",
    "        RDKit mol 객체가 있는 컬럼명 (None이면 SMILES에서 생성)\n",
    "    ecfp_radius : int, default=2\n",
    "        ECFP의 반지름\n",
    "    ecfp_bits : int, default=2048\n",
    "        ECFP의 비트 수\n",
    "    n_clusters : int, optional\n",
    "        클러스터 수 (None이면 자동 계산)\n",
    "    random_state : int, default=42\n",
    "        랜덤 시드\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    Tuple[pd.DataFrame, pd.DataFrame]\n",
    "        (train_df, val_df) 튜플\n",
    "    \"\"\"\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # 1. ECFP 피처 생성\n",
    "    print(\"ECFP 피처 생성 중...\")\n",
    "\n",
    "    morgan_gen = GetMorganGenerator(radius=ecfp_radius, fpSize=ecfp_bits)\n",
    "\n",
    "    ecfp_features = []\n",
    "    valid_indices = []\n",
    "    \n",
    "    for idx, row in df_copy.iterrows():\n",
    "        try:\n",
    "            # mol 객체가 있으면 사용, 없으면 SMILES에서 생성\n",
    "            if mol_col and mol_col in df_copy.columns and pd.notna(row[mol_col]):\n",
    "                mol = row[mol_col]\n",
    "            else:\n",
    "                mol = Chem.MolFromSmiles(row[smiles_col])\n",
    "            \n",
    "            if mol is not None:\n",
    "                # ECFP 생성\n",
    "                fp = morgan_gen.GetFingerprint(mol)\n",
    "                ecfp_features.append(np.array(fp))\n",
    "                valid_indices.append(idx)\n",
    "            else:\n",
    "                print(f\"Warning: 인덱스 {idx}에서 분자 생성 실패\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: 인덱스 {idx}에서 오류 발생: {e}\")\n",
    "            continue\n",
    "    \n",
    "    if len(ecfp_features) == 0:\n",
    "        raise ValueError(\"유효한 ECFP 피처를 생성할 수 없습니다.\")\n",
    "    \n",
    "    # 유효한 데이터만 필터링\n",
    "    df_valid = df_copy.loc[valid_indices].reset_index(drop=True)\n",
    "    ecfp_matrix = np.array(ecfp_features)\n",
    "    \n",
    "    print(f\"유효한 분자 수: {len(ecfp_features)}\")\n",
    "    \n",
    "    # 2. 클러스터 수 결정\n",
    "    if n_clusters is None:\n",
    "        # 적절한 클러스터 수 자동 계산 (데이터 크기의 제곱근 정도)\n",
    "        n_clusters = max(2, int(np.sqrt(len(ecfp_features)) / 2))\n",
    "        # validation 비율을 맞추기 위해 조정\n",
    "        n_clusters = min(n_clusters, int(1 / val_ratio))\n",
    "    \n",
    "    print(f\"클러스터 수: {n_clusters}\")\n",
    "    \n",
    "    # 3. K-means 클러스터링\n",
    "    print(\"클러스터링 수행 중...\")\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=random_state, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(ecfp_matrix)\n",
    "    \n",
    "    # 4. 클러스터별 크기 계산\n",
    "    unique_clusters, cluster_counts = np.unique(cluster_labels, return_counts=True)\n",
    "    cluster_info = list(zip(unique_clusters, cluster_counts))\n",
    "    cluster_info.sort(key=lambda x: x[1], reverse=True)  # 크기 순 정렬\n",
    "    \n",
    "    print(\"클러스터 정보:\")\n",
    "    for cluster_id, count in cluster_info:\n",
    "        print(f\"  클러스터 {cluster_id}: {count}개 분자\")\n",
    "    \n",
    "    # 5. validation 클러스터 선택\n",
    "    # 목표 validation 크기\n",
    "    target_val_size = int(len(df_valid) * val_ratio)\n",
    "    \n",
    "    # 클러스터를 하나씩 validation에 할당하면서 목표 크기에 근접하도록\n",
    "    val_clusters = []\n",
    "    current_val_size = 0\n",
    "    \n",
    "    for cluster_id, count in cluster_info:\n",
    "        if current_val_size + count <= target_val_size * 1.2:  # 20% 여유\n",
    "            val_clusters.append(cluster_id)\n",
    "            current_val_size += count\n",
    "        if current_val_size >= target_val_size * 0.8:  # 80% 이상이면 중단\n",
    "            break\n",
    "    \n",
    "    # 6. train/validation 분리\n",
    "    val_mask = np.isin(cluster_labels, val_clusters)\n",
    "    train_mask = ~val_mask\n",
    "    \n",
    "    train_df = df_valid[train_mask].reset_index(drop=True)\n",
    "    val_df = df_valid[val_mask].reset_index(drop=True)\n",
    "    \n",
    "    # 7. 결과 요약\n",
    "    actual_val_ratio = len(val_df) / len(df_valid)\n",
    "    \n",
    "    print(f\"\\n분리 결과:\")\n",
    "    print(f\"  전체: {len(df_valid)}개\")\n",
    "    print(f\"  Train: {len(train_df)}개 ({len(train_df)/len(df_valid)*100:.1f}%)\")\n",
    "    print(f\"  Validation: {len(val_df)}개 ({actual_val_ratio*100:.1f}%)\")\n",
    "    print(f\"  Validation 클러스터: {val_clusters}\")\n",
    "    \n",
    "    # 8. 클러스터 간 유사도 분석\n",
    "    print(\"\\n클러스터 간 유사도 분석 중...\")\n",
    "    train_clusters = [c for c in unique_clusters if c not in val_clusters]\n",
    "    \n",
    "    # 각 클러스터의 중심점 계산\n",
    "    train_centroids = []\n",
    "    val_centroids = []\n",
    "    \n",
    "    for cluster_id in train_clusters:\n",
    "        cluster_mask = cluster_labels == cluster_id\n",
    "        centroid = np.mean(ecfp_matrix[cluster_mask], axis=0)\n",
    "        train_centroids.append(centroid)\n",
    "    \n",
    "    for cluster_id in val_clusters:\n",
    "        cluster_mask = cluster_labels == cluster_id\n",
    "        centroid = np.mean(ecfp_matrix[cluster_mask], axis=0)\n",
    "        val_centroids.append(centroid)\n",
    "    \n",
    "    if train_centroids and val_centroids:\n",
    "        # Tanimoto 유사도 계산 (Jaccard 유사도)\n",
    "        train_centroids = np.array(train_centroids)\n",
    "        val_centroids = np.array(val_centroids)\n",
    "        \n",
    "        # 이진화 (임계값 0.5)\n",
    "        train_centroids_bin = (train_centroids > 0.5).astype(int)\n",
    "        val_centroids_bin = (val_centroids > 0.5).astype(int)\n",
    "        \n",
    "        # Jaccard 거리 계산 (1 - Jaccard 유사도)\n",
    "        distances = pairwise_distances(train_centroids_bin, val_centroids_bin, metric='jaccard')\n",
    "        min_distance = np.min(distances)\n",
    "        max_similarity = 1 - min_distance\n",
    "        \n",
    "        print(f\"  Train-Validation 클러스터 간 최대 Tanimoto 유사도: {max_similarity:.3f}\")\n",
    "        print(f\"  Train-Validation 클러스터 간 최소 Jaccard 거리: {min_distance:.3f}\")\n",
    "    \n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de207eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECFP 피처 생성 중...\n",
      "유효한 분자 수: 25753\n",
      "클러스터 수: 3\n",
      "클러스터링 수행 중...\n",
      "클러스터 정보:\n",
      "  클러스터 1: 17776개 분자\n",
      "  클러스터 0: 5139개 분자\n",
      "  클러스터 2: 2838개 분자\n",
      "\n",
      "분리 결과:\n",
      "  전체: 25753개\n",
      "  Train: 20614개 (80.0%)\n",
      "  Validation: 5139개 (20.0%)\n",
      "  Validation 클러스터: [0]\n",
      "\n",
      "클러스터 간 유사도 분석 중...\n",
      "  Train-Validation 클러스터 간 최대 Tanimoto 유사도: 0.444\n",
      "  Train-Validation 클러스터 간 최소 거리: 0.556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tech/Hawon/dacon-jump-ai-2025/.venv/lib/python3.10/site-packages/sklearn/metrics/pairwise.py:2463: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"/home/tech/Hawon/dacon-jump-ai-2025/data/250714_preprocessed_HW_V2.pkl\")\n",
    "train_df, val_df = ecfp_cluster_train_val_split(df, val_ratio=0.2, n_clusters=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f8528ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = {}\n",
    "\n",
    "split[\"train\"] = train_df.medai_id.values.tolist()\n",
    "split[\"validation\"] = val_df.medai_id.values.tolist()\n",
    "\n",
    "with open(\"../data/tr_vl_split_250717.json\", \"w\") as f:\n",
    "    json.dump(split, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
